'''
Generates a training output Images for the LLM model to describe the input and output grids of a challenge.
'''

import base64
import os
import time
from classes.data_loader import DataLoader

import numpy as np

from openai import OpenAI
from pydantic import BaseModel

from utils.generate_aug_training import get_augmented_training_examples

# Initialize the OpenAI client
client = OpenAI(
    api_key='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')


def generate_nld_of_example(sample: int = None):
    """
    Generates a natural language description of images using an LLM model to describe the input and output grids of a challenge.
    """

    files = [f for f in os.listdir('output/singles') if os.path.isfile(os.path.join('output/singles', f))]

    if sample is not None:
        files = files[:sample]

    batches = {}
    for f in files:
        batch = f.split('_')[0]
        if batch not in batches:
            batches[batch] = []
        batches[batch].append(f)

    responses = {}
    for batch in batches:
        images_encoded = []
        for f in batches[batch]:
            with open(f'output/singles/{f}', 'rb') as img_file:
                encoded_image = base64.b64encode(img_file.read()).decode('utf-8')
                images_encoded.append(encoded_image)

        context = (
            "You are the world's best natural language describer of logic puzzles presented in grid format. "
            "These grids represent abstract logic problems where the challenge is to understand and describe "
            "the transformation that occurs between the input and output grids. Your task is to analyze the "
            "patterns, changes, and rules governing these transformations with exceptional detail and clarity."
        )
        prompt = (
            f"{context}\n\n"
            f"Here are some training examples for the challenge {batch}. Describe, in detail, the transformation "
            f"that occurs between the input and output grids. Focus on identifying patterns, rules, and logical "
            f"operations that explain the changes observed. Be as precise and comprehensive as possible in your description."
        )

        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt}
                ]
            }
        ]

        for image in images_encoded:
            messages[0]["content"].append(
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image}"}
                }
            )

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            max_tokens=300
        )

        reply = response.choices[0].message.content

        responses[batch] = reply

    return responses


class OutputGrid(BaseModel):
    outputGrid: list[list[int]]

def grid_to_str(grid: list[list[int]]):
    grid_strs = []
    for row in grid:
        row_str = ", ".join([str(x) for x in row])
        grid_strs.append("["+row_str+"]")
    return "[" + ", ".join(grid_strs) + "]"


def generate_output_grid(inputGrids_as_str, systemPrompt="", max_tokens=300, req_interval=0.01):
    """
    Takes a list of str, each in the following form "[I]->[O], [I]->[O], [I]->[O], [I]->",
    pass to OpenAI and return the model's replies
    :param inputGrids_as_str: list[str] (or str if only one instance)
    :param systemPrompt: str
    :param max_tokens: max tokens to be generated
    :param req_interval: float
    :return: list[list[list[int]], a list of 2D output grids generated by the model
    """

    if isinstance(inputGrids_as_str, str):
        inputGrids_as_str = [inputGrids_as_str]

    replies = []
    for grids in inputGrids_as_str:
        messages = [{"role": "user",
                     "content": f"You are given example pairs of input and output grids "
                                f"which follow the same transformation rule. "
                                f"Infer this rule, transform the final input grid and predict its corresponding output grid."
                                f"Return the output grid as a list of list of integers:\n\n{grids}"}]

        if systemPrompt:
            messages.insert(0, {"role": "system", "content": systemPrompt})

        response = client.beta.chat.completions.parse(
            model="gpt-4o",
            messages=messages,
            max_completion_tokens=max_tokens,
            response_format=OutputGrid,
        )

        parsed_response = response.choices[0].message.parsed
        print(f"SAMPLE MODEL RESPONSE: {parsed_response}")
        print(type(parsed_response))
        replies.append(response.choices[0].message.parsed.outputGrid)

        if req_interval:
            # in case hitting API rate limit
            # https://platform.openai.com/docs/guides/rate-limits
            time.sleep(req_interval)

    return replies


def demo(challenge_id="007bbfb7", dl=None, training_data=None):
    if not dl:
        dl = DataLoader()
    if not training_data:
        training_data = dl.load_dataset("training",
                                        dataset_locations_override=("../../data/arc-agi_training_challenges.json",
                                                                    "../../data/arc-agi_training_solutions.json"))

    unique_keys = set(training_data.keys())
    print(f"Number of training challenges: {len(unique_keys)}")

    challenge_data = dl.get_specific_sample(challenge_id)

    print("Test Input:", challenge_data["test_input"])
    print("Training Examples:", challenge_data["train_examples"])
    print("Solution:", challenge_data["solution"])
    print("Get augmented training examples")
    training_examples_cid = get_augmented_training_examples(dl, challenge_id, visualize=False)
    print("Training examples augmented.")
    example_permutation = training_examples_cid[0]

    def prepare_instance(io_pairs):
        io_pairs_strings = []
        gt = None
        for i, training_example_io_pair in enumerate(io_pairs):
            inputGrid, outputGrid = training_example_io_pair[0], training_example_io_pair[1]
            inputGridAsString, outputGridAsString = grid_to_str(inputGrid["permutation"]), grid_to_str(outputGrid["permutation"])
            if i < len(example_permutation)-1:
                io_pairs_strings.append(f"{inputGridAsString} -> {outputGridAsString}")
            else:
                io_pairs_strings.append(f"{inputGridAsString} ->")
                gt = outputGrid["permutation"]
        gridsAsString = "\n".join(io_pairs_strings)

        return gridsAsString, gt

    print("Preprocessing grids into strings")
    inputStr, groundTruthGrid = prepare_instance(example_permutation)
    print(inputStr)

    model_response = generate_output_grid(inputStr, "You are a helpful assistant")[0]

    def pred_v_gt(predGrid, gtGrid, print_result=True):
        predGrid = np.array(predGrid)
        gtGrid = np.array(gtGrid)
        if predGrid.shape != gtGrid.shape:
            print(f"Grid shape mismatch - gt: {gtGrid.shape}, pred: {predGrid.shape}")
            return gtGrid.shape[0]*gtGrid.shape[1]  # counts as getting all cells wrong

        diffGrid = predGrid != gtGrid
        error = np.sum(diffGrid)
        if print_result:
            print("Printing difference grid (TRUE = mismatch between pred and gt found:")
            print(diffGrid)

        return error

    err = pred_v_gt(model_response, groundTruthGrid)
    print(f"Ground truth grid: \n{groundTruthGrid}")
    if not err:
        print(f"Model answered correctly.")
    else:
        print(f"Model answered incorrectly. No. of wrong cells = {err}. ")
        print(f"Model predicted grid: \n{np.array(model_response)}")


if __name__ == "__main__":
    demo()
